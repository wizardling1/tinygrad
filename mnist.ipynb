{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU\n"
     ]
    }
   ],
   "source": [
    "from tinygrad import Device\n",
    "print(Device.DEFAULT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tinygrad import Tensor, nn\n",
    "\n",
    "class Model:\n",
    "    def __init__(self):\n",
    "        self.l1 = nn.Conv2d(1, 32, kernel_size=(3,3))\n",
    "        self.l2 = nn.Conv2d(32,64,kernel_size=(3,3))\n",
    "        self.l3 = nn.Linear(1600, 10)\n",
    "\n",
    "    def __call__(self, x:Tensor) -> Tensor:\n",
    "        x = self.l1(x).relu().max_pool2d((2,2))\n",
    "        x = self.l2(x).relu().max_pool2d((2,2))\n",
    "        return self.l3(x.flatten(1).dropout(0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 1, 28, 28) dtypes.uchar (60000,) dtypes.uchar\n"
     ]
    }
   ],
   "source": [
    "from tinygrad.nn.datasets import mnist\n",
    "X_train, Y_train, X_test, Y_test = mnist()\n",
    "print(X_train.shape, X_train.dtype, Y_train.shape, Y_train.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07479999959468842\n"
     ]
    }
   ],
   "source": [
    "model = Model()\n",
    "acc = (model(X_test).argmax(axis=1) == Y_test).mean()\n",
    "# NOTE: tinygrad is lazy, and hasn't actually run anything by this point\n",
    "print(acc.item())  # ~10% accuracy, as expected from a random model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = nn.optim.Adam(nn.state.get_parameters(model))\n",
    "batch_size = 128\n",
    "def step():\n",
    "  Tensor.training = True  # makes dropout work\n",
    "  samples = Tensor.randint(batch_size, high=X_train.shape[0])\n",
    "  X, Y = X_train[samples], Y_train[samples]\n",
    "  optim.zero_grad()\n",
    "  loss = model(X).sparse_categorical_crossentropy(Y).backward()\n",
    "  optim.step()\n",
    "  return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3.9447798229994078,\n",
       " 1.2505387560013332,\n",
       " 0.8776281890022801,\n",
       " 0.8732907150006213,\n",
       " 0.9003348250007548]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import timeit\n",
    "timeit.repeat(step, repeat=5, number=1)\n",
    "#[0.08268719699981375,\n",
    "# 0.07478952900009972,\n",
    "# 0.07714716600003158,\n",
    "# 0.07785399599970333,\n",
    "# 0.07605237000007037]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tinygrad import TinyJit\n",
    "jit_step = TinyJit(step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9349846709992562,\n",
       " 0.8772227720000956,\n",
       " 0.8776176799983659,\n",
       " 0.8782093999980134,\n",
       " 0.8755927239981247]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import timeit\n",
    "timeit.repeat(jit_step, repeat=5, number=1)\n",
    "# [0.2596786549997887,\n",
    "#  0.08989566299987928,\n",
    "#  0.0012115650001760514,\n",
    "#  0.001010227999813651,\n",
    "#  0.0012164899999334011]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step    0, loss 1.43, acc 78.71%\n",
      "step  100, loss 0.34, acc 94.34%\n",
      "step  200, loss 0.19, acc 95.59%\n",
      "step  300, loss 0.24, acc 96.66%\n",
      "step  400, loss 0.22, acc 97.16%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m7000\u001b[39m):\n\u001b[0;32m----> 2\u001b[0m   loss \u001b[38;5;241m=\u001b[39m \u001b[43mjit_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m step\u001b[38;5;241m%\u001b[39m\u001b[38;5;241m100\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m      4\u001b[0m     Tensor\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/gitclones/tinygrad/tinygrad/engine/jit.py:310\u001b[0m, in \u001b[0;36mTinyJit.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    307\u001b[0m   \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcaptured\u001b[38;5;241m.\u001b[39mexpected_names \u001b[38;5;241m==\u001b[39m names, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124margs mismatch in JIT: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcaptured\u001b[38;5;241m.\u001b[39mexpected_names\u001b[38;5;132;01m=}\u001b[39;00m\u001b[38;5;124m != \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnames\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    308\u001b[0m   \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcaptured\u001b[38;5;241m.\u001b[39mexpected_st_vars_dtype_device \u001b[38;5;241m==\u001b[39m st_vars_dtype_device, \\\n\u001b[1;32m    309\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124margs mismatch in JIT: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcaptured\u001b[38;5;241m.\u001b[39mexpected_st_vars_dtype_device\u001b[38;5;132;01m=}\u001b[39;00m\u001b[38;5;124m != \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mst_vars_dtype_device\u001b[38;5;132;01m=}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 310\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_buffers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvar_vals\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcnt \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    313\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "File \u001b[0;32m~/gitclones/tinygrad/tinygrad/engine/jit.py:190\u001b[0m, in \u001b[0;36mCapturedJit.__call__\u001b[0;34m(self, input_buffers, var_vals)\u001b[0m\n\u001b[1;32m    187\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_first_run \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m DEBUG \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_cache) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m: \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjit execs \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_cache)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m kernels\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 190\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ei \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_cache: \u001b[43mei\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvar_vals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_clear_inputs()\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mret\n",
      "File \u001b[0;32m~/gitclones/tinygrad/tinygrad/engine/realize.py:127\u001b[0m, in \u001b[0;36mExecItem.run\u001b[0;34m(self, _var_vals, wait, jit, do_update_stats)\u001b[0m\n\u001b[1;32m    125\u001b[0m var_vals \u001b[38;5;241m=\u001b[39m {} \u001b[38;5;28;01mif\u001b[39;00m _var_vals \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m _var_vals\n\u001b[1;32m    126\u001b[0m bufs \u001b[38;5;241m=\u001b[39m [cast(Buffer, x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbufs] \u001b[38;5;28;01mif\u001b[39;00m jit \u001b[38;5;28;01melse\u001b[39;00m [cast(Buffer, x)\u001b[38;5;241m.\u001b[39mensure_allocated() \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbufs]\n\u001b[0;32m--> 127\u001b[0m et \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprg\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbufs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvar_vals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwait\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mDEBUG\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m do_update_stats:\n\u001b[1;32m    129\u001b[0m   GlobalCounters\u001b[38;5;241m.\u001b[39mkernel_count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/gitclones/tinygrad/tinygrad/engine/realize.py:67\u001b[0m, in \u001b[0;36mCompiledRunner.__call__\u001b[0;34m(self, rawbufs, var_vals, wait)\u001b[0m\n\u001b[1;32m     65\u001b[0m   lra[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocal_size\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(local_size)\n\u001b[1;32m     66\u001b[0m   \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(local_size) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlocal size must have len 3\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_prg\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_buf\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrawbufs\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mlra\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mvar_vals\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvars\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwait\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/gitclones/tinygrad/tinygrad/device.py:272\u001b[0m, in \u001b[0;36mCPUProgram.__call__\u001b[0;34m(self, vals, wait, *bufs)\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;66;03m# NOTE: replace this by --target={host's triple}-elf in clang args once we only support macos sequoia and later.\u001b[39;00m\n\u001b[1;32m    267\u001b[0m \u001b[38;5;66;03m# Apple relaxes abi requirement for stack arguments to always be at least 8 byte aligned on arm64\u001b[39;00m\n\u001b[1;32m    268\u001b[0m \u001b[38;5;66;03m# https://developer.apple.com/documentation/xcode/writing-arm64-code-for-apple-platforms\u001b[39;00m\n\u001b[1;32m    269\u001b[0m \u001b[38;5;66;03m# This hack is required because clang/llvm bug doesn't allow us to just use {host's triple}+'-elf' (relocation failures)\u001b[39;00m\n\u001b[1;32m    270\u001b[0m \u001b[38;5;66;03m# The bug was fixed in https://github.com/llvm/llvm-project/commit/454cc36630296262cdb6360b60f90a64a97f7f1a but was only backported to xcode 16+\u001b[39;00m\n\u001b[1;32m    271\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m platform\u001b[38;5;241m.\u001b[39mmachine() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marm64\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m OSX: args \u001b[38;5;241m=\u001b[39m args[:\u001b[38;5;241m8\u001b[39m] \u001b[38;5;241m+\u001b[39m [ctypes\u001b[38;5;241m.\u001b[39mc_int64(a) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(a, \u001b[38;5;28mint\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m a \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m args[\u001b[38;5;241m8\u001b[39m:]]\n\u001b[0;32m--> 272\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcpu_time_execution\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfxn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/gitclones/tinygrad/tinygrad/helpers.py:265\u001b[0m, in \u001b[0;36mcpu_time_execution\u001b[0;34m(cb, enable)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcpu_time_execution\u001b[39m(cb, enable):\n\u001b[1;32m    264\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m enable: st \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mperf_counter()\n\u001b[0;32m--> 265\u001b[0m   \u001b[43mcb\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    266\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m enable: \u001b[38;5;28;01mreturn\u001b[39;00m time\u001b[38;5;241m.\u001b[39mperf_counter()\u001b[38;5;241m-\u001b[39mst\n",
      "File \u001b[0;32m~/gitclones/tinygrad/tinygrad/device.py:272\u001b[0m, in \u001b[0;36mCPUProgram.__call__.<locals>.<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;66;03m# NOTE: replace this by --target={host's triple}-elf in clang args once we only support macos sequoia and later.\u001b[39;00m\n\u001b[1;32m    267\u001b[0m \u001b[38;5;66;03m# Apple relaxes abi requirement for stack arguments to always be at least 8 byte aligned on arm64\u001b[39;00m\n\u001b[1;32m    268\u001b[0m \u001b[38;5;66;03m# https://developer.apple.com/documentation/xcode/writing-arm64-code-for-apple-platforms\u001b[39;00m\n\u001b[1;32m    269\u001b[0m \u001b[38;5;66;03m# This hack is required because clang/llvm bug doesn't allow us to just use {host's triple}+'-elf' (relocation failures)\u001b[39;00m\n\u001b[1;32m    270\u001b[0m \u001b[38;5;66;03m# The bug was fixed in https://github.com/llvm/llvm-project/commit/454cc36630296262cdb6360b60f90a64a97f7f1a but was only backported to xcode 16+\u001b[39;00m\n\u001b[1;32m    271\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m platform\u001b[38;5;241m.\u001b[39mmachine() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marm64\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m OSX: args \u001b[38;5;241m=\u001b[39m args[:\u001b[38;5;241m8\u001b[39m] \u001b[38;5;241m+\u001b[39m [ctypes\u001b[38;5;241m.\u001b[39mc_int64(a) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(a, \u001b[38;5;28mint\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m a \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m args[\u001b[38;5;241m8\u001b[39m:]]\n\u001b[0;32m--> 272\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cpu_time_execution(\u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfxn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m, enable\u001b[38;5;241m=\u001b[39mwait)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for step in range(7000):\n",
    "  loss = jit_step()\n",
    "  if step%100 == 0:\n",
    "    Tensor.training = False\n",
    "    acc = (model(X_test).argmax(axis=1) == Y_test).mean().item()\n",
    "    print(f\"step {step:4d}, loss {loss.item():.2f}, acc {acc*100.:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Tensor <UOp CPU (4, 4) float (<Ops.ADD: 48>, None)> on CPU with grad None>\n"
     ]
    }
   ],
   "source": [
    "from tinygrad import Tensor\n",
    "\n",
    "a = Tensor.empty(4,4)\n",
    "b = Tensor.empty(4,4)\n",
    "print((a+b))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tinygrad",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
